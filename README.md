# #-ğŸ§ -RAG-AI-Platform


Your Local Retrieval-Augmented Generation Assistant for Enterprises

ğŸš€ Overview

Enterprise RAG AI Platform is a local, privacy-friendly, and CPU-efficient system that allows enterprises to query their private documents intelligently using Retrieval-Augmented Generation (RAG).
Built with FastAPI, Streamlit, ChromaDB, and local embedding + LLM models, it provides a complete end-to-end solution for document ingestion, semantic retrieval, and intelligent answering.

ğŸ”’ 100% local â€” your documents never leave your system.

ğŸŒŸ Key Features

âœ… Document Ingestion

Upload multiple PDF, TXT, or CSV files

Automatically extract and embed text into a Chroma vector store

âœ… Retrieval-Augmented Generation

Fetches most relevant document chunks for each query

Combines them with your question to generate context-aware answers

âœ… Interactive UI

Built with Streamlit for real-time chat-style Q&A

Beautiful dark/light themes

Animated AI responses

âœ… Modular FastAPI Backend

/ingest â†’ Upload and embed documents

/query â†’ Ask questions and get intelligent answers

âœ… Completely Offline

Uses CPU-based local embedding and generation models

No API keys or cloud dependencies

ğŸ§© Project Architecture
rag-ai-platform/
â”‚
â”œâ”€â”€ main.py                 # FastAPI entry point
â”œ        # Streamlit frontend UI
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py              # Core RAG backend logic (FastAPI app)
â”‚   â”œâ”€â”€ ingestion.py        # PDF/TXT data loading utilities
â”‚   â”œâ”€â”€ embed_store.py      # Embedding and Chroma vector store logic
â”‚   â”œâ”€â”€ retriever.py        # Semantic retrieval from vector DB
â”‚   â”œâ”€â”€ generator.py       # Local LLM integration
â”‚   |--streamlit.py         # Streamlit frontend UI
â”œâ”€â”€ data/                   # Folder where uploaded docs are stored
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/veneel77/rag-ai-platform.git
cd rag-ai-platform

2ï¸âƒ£ Create a virtual environment
python -m venv .venv
.venv\Scripts\activate     # On Windows
# OR
source .venv/bin/activate  # On Linux/Mac

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Start the backend server
uvicorn main:app --reload


Your backend runs at ğŸ‘‰ http://127.0.0.1:8000

5ï¸âƒ£ Start the Streamlit frontend
streamlit run streamlit_app.py


Your frontend runs at ğŸ‘‰ http://localhost:8502

ğŸ§° Requirements
fastapi
uvicorn
streamlit
chromadb
PyPDF2
pandas
sentence-transformers
langchain
requests

ğŸ§± Future Developments

Hereâ€™s whatâ€™s planned for future releases of the RAGFlow AI Platform:

ğŸ”¹ Advanced Document Management

Upload entire folders for batch ingestion

Add document deletion, re-indexing, and update options

Metadata tagging for enterprise datasets (author, department, timestamp)

ğŸ”¹ Model Enhancements

Integrate local HuggingFace LLMs (e.g., Mistral, Phi-3-mini, Llama 3)

Support hybrid retrieval (BM25 + Vector)

Add fine-tuning support for enterprise domain-specific models

ğŸ”¹ Improved UI/UX

Persistent chat history

Visual analytics for retrieved chunks

Dynamic theme customization (brand colors, fonts, enterprise mode)

ğŸ”¹ Enterprise-Grade Features

User authentication and session management

Role-based access control for document visibility

Deployable via Docker, Azure, or AWS ECS

ğŸ”¹ Integrations

Connect with SharePoint, Confluence, or local drives for ingestion

Integration with email summarization and HR analytics

ğŸš§ Problem Solving & Scalability Plans
Problem	Current Status	Future Solution
Large Document Chunking	Long PDFs exceed context window	Add dynamic chunk splitting & sliding window retrieval
Slow Inference on CPU	GPT4All is CPU-based	Allow GPU/quantized model options
Timeouts on long queries	Fixed timeout (180s)	Stream async responses in real time
Error Handling	Basic HTTP try/except	Centralized FastAPI error handler
Search Relevance	Vector-only retrieval	Combine keyword + semantic hybrid retrieval
Lack of live ingestion	File upload via Streamlit only	Auto-ingestion from watched directory or API call
Scaling for Multi-user	Local session	Plan: Redis-based user sessions + multi-container deployment
ğŸ§‘â€ğŸ’» Developer Info

Project: RAGFlow AI Platform
Developer: ğŸ§  Veneel Kumar A
Year: 2025
License: MIT
Built With: â¤ï¸ Python, Streamlit, and FastAPI

ğŸ’¬ â€œEmpowering enterprises with local, secure, and intelligent document understanding.â€